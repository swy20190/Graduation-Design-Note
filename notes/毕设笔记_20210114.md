# 毕设笔记(2021/1/14)

## 目前文献总结
之前着重于调研姿态识别技术，方向其实走偏了。之后换了一下搜索关键词，简单地考察了一下2005年以来的摔倒检测(fall detection)技术，收获颇丰，如下：
- 基于计算机视觉的方法
	- 基于轮廓检测，检查包围盒(bounding box)长宽比
	- 基于轮廓检测，检擦人轮廓长轴(long axis)的指向
		- 摄像机为水平放置，则长轴与竖直线夹角过大，视为跌倒
		- 摄像机为垂直放置，位于房间天花板正中央，则长轴不指向图片中央，视为跌倒
	- 基于轮廓检测的弊端在于，系统只能识别运动的前景，并把它当作老人。如果老人身边有其他的运动物体，如辅助行走的支架，系统无法区分支架与老人。
- 基于穿戴式传感器的方法
	- 腰部佩戴的加速度传感器，这是2005-2008年，摔倒检测领域最初的方案
	- 基于智能手机传感器数据的方法，可引入简单的机器学习模型如SVM，数据集有MobiFall
- 基于非接触式传感器的方法
	- 雷达，kinect景深摄像机
	- 在广义上看，计算机视觉的RGB摄像机也可以归于此类

## 目前思路
考虑到误报的代价，我觉得应当首先处理静态状态下老人平躺状态的检测，而不是之前计划的动态过程。也就是说，输入的数据应当为单帧。
单帧图像首先使用openpose处理，得到关键点坐标。基于这些坐标，(1)首先计算大腿与竖直线夹角以及关键点的包围盒长宽比；(2)其次，计算几根关键骨骼的长度比例。(1)得到的数据可以用决策树模型处理，(2)得到的数据可以用SVM处理。这二者应当可以综合起来，会需要用到多层神经网络（不确定，因为我目前正在自学这部分).

## 当前计划
- 使用openpose预处理数据，数据集为[http://www.falldataset.com](http://www.falldataset.com/)，尝试将图片转为上面说的坐标，长度比，角度等等数据
- 继续阅读文献，重写文献综述(可能在春节后完成)


## 目前的困难
找到的文献大部分不公开他们的数据集。那么如果将来要将我的算法与他们的做比较，改如何量化二者之间的性能呢？还是说直接引用他们的实验结果，和我在我自己的数据集上跑的结果比较就可以了呢？





















